"""
Assistente AcadÃªmico com RAG - VersÃ£o MVP
Fase 1: Estrutura bÃ¡sica funcional
"""
import streamlit as st
import os
from config import UI_CONFIG, LLM_CONFIG, EMBEDDING_CONFIG, EMBEDDING_OPTIONS, DEFAULT_EMBEDDING, CHROMA_DIR
import datetime


current_year = datetime.date.today().year

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title=UI_CONFIG["page_title"],
    page_icon=UI_CONFIG["page_icon"],
    layout=UI_CONFIG["layout"]
)

# CabeÃ§alho
st.title("ğŸ“ Assistente AcadÃªmico com IA")
st.caption("AnÃ¡lise inteligente de papers cientÃ­ficos usando RAG")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ ConfiguraÃ§Ãµes")
    
    # Input da API Key
    api_key = st.text_input(
        "Groq API Key",
        type="password",
        help="Obtenha sua chave em: https://console.groq.com/"
    )
    
    if api_key:
        os.environ["GROQ_API_KEY"] = api_key
        st.success("âœ… API Key configurada")
    
    st.divider()

    st.subheader("ğŸ§  Modelo de Embedding")

    from config import EMBEDDING_OPTIONS, DEFAULT_EMBEDDING

    selected_embedding = st.selectbox(
        "Escolha o modelo de embedding",
        options=list(EMBEDDING_OPTIONS.keys()),
        index=list(EMBEDDING_OPTIONS.keys()).index(DEFAULT_EMBEDDING),
        help="Diferentes modelos tÃªm trade-offs entre velocidade e qualidade"
        )
    
    embedding_info = EMBEDDING_OPTIONS[selected_embedding]
    
    with st.expander("â„¹ï¸ Detalhes do Modelo", expanded=False):
        st.write(f"**DescriÃ§Ã£o:** {embedding_info['description']}")
        st.write(f"**DimensÃµes:** {embedding_info['dimensions']}")
        st.write(f"**Velocidade:** {embedding_info['speed']}")
        st.write(f"**Qualidade:** {embedding_info['quality']}")
    
    st.session_state.selected_embedding_model = embedding_info["model_name"]
    st.session_state.selected_embedding_name = selected_embedding
    
    st.divider()
    
    st.subheader("ğŸ“š Sobre o Projeto")
    st.info(
        """
        Este assistente utiliza **RAG (Retrieval-Augmented Generation)** 
        para analisar papers cientÃ­ficos e responder perguntas sobre:
        
        - Metodologias utilizadas
        - Resultados principais
        - ComparaÃ§Ã£o entre estudos
        - SÃ­ntese de literatura
        """
    )
    
    st.divider()
    
    st.markdown("**Status do Sistema:**")
    st.write(f"ğŸ“¦ Modelo: `{LLM_CONFIG['model']}`")
    st.write(f"ğŸŒ¡ï¸ Temperatura: `{LLM_CONFIG['temperature']}`")

# VerificaÃ§Ã£o de API Key
if not api_key:
    st.warning("âš ï¸ Configure sua Groq API Key na barra lateral para comeÃ§ar")
    st.stop()

# Ãrea principal (por enquanto apenas placeholder)
st.markdown("---")
st.subheader("ğŸ“„ Upload de Papers")

uploaded_files = st.file_uploader(
    "FaÃ§a upload de um ou mais papers (PDF)",
    type=["pdf"],
    accept_multiple_files=True,
    help="VocÃª pode enviar mÃºltiplos PDFs para anÃ¡lise comparativa"
)

if uploaded_files:
    st.success(f"âœ… {len(uploaded_files)} arquivo(s) carregado(s)")
    
    st.markdown("### ğŸ“‹ Metadados dos Papers")
    st.info("ğŸ’¡ Preencha os metadados para melhorar as buscas por autor/ano. Deixe em branco se nÃ£o souber.")

    # incializa dicionÃ¡rio de metadados se nÃ£o existr
    if "manual_metadata" not in st.session_state:
        st.session_state.manual_metadata = {}

    #cria formulÃ¡rio para cada arquivo
    metadata_forms = []
    for i, uploaded_file in enumerate(uploaded_files):
        with st.expander(f"ğŸ“„ {uploaded_file.name}", expanded=(i==0)):
            col1, col2, col3 = st.columns(3)

            with col1:
                author = st.text_input(
                    "Primeiro Autor (sobrenome)",
                    key=f"author_{i}",
                    placeholder="Ex: Silva",
                    help="Sobrenome do primeiro autor"
                )

            with col2:
                metadata = st.session_state.manual_metadata.get(uploaded_file.name, {})
                year = st.number_input(
                    "Ano de PublicaÃ§Ã£o",
                    min_value=0,              # Permite papers histÃ³ricos
                    max_value=current_year,   # Bloqueia anos no futuro
                    value=metadata.get("year", current_year), # Usa o ano extraÃ­do pelo Llama ou o atual
                    key=f"year_{i}",
                    help="Ano de publicaÃ§Ã£o do paper"
                )
            with col3:
                title = st.text_input(
                    "Titulo (opc)",
                    key=f"title_{i}",
                    placeholder="Ex: Machie=ne Learning...",
                    help="TÃ­tulo do paper (opcional)"
                )

            #salva no session_state
            st.session_state.manual_metadata[uploaded_file.name] = {
                "author": author if author else None,
                "year": year,
                "title": title if title else None
            }
    st.divider()


    if st.button("ğŸ“Š Processar Documentos", type="primary"):

        # Importa o processador
        from src.document_processor import DocumentProcessor
        from src.utils import get_document_stats

        #Inicializa o processador
        processor = DocumentProcessor()
        #Processa cada PDF
        all_results = []

        with st.spinner("Processando PDFs..."):
            for uploaded_file in uploaded_files:
                result = processor.process_pdf(uploaded_file, uploaded_file.name)
                all_results.append(result)

            manual_meta = st.session_state.manual_metadata.get(uploaded_file.name, {})

            for key in ["author", "year", "title"]:
                if value := manual_meta.get(key):
                    result["metadata"][key] = value
            
            # Atualiza chunks com metadados corrigidos
            if result["success"]:
                updates = {k: v for k, v in manual_meta.items() if v and k in ["author", "year", "title"]}
                for chunk in result["documents"]:
                    chunk.metadata |= updates
        
        # Exibe resultados
        st.markdown("### ğŸ“ˆ Resultados do Processamento")

        for i, result in enumerate(all_results, 1):
            if result["success"]:
                st.success(f"âœ… **{result['metadata']['source_file']}**")
        
         #Mostra metadados extraÃ­dos
                meta = result["metadata"]
                display_map = {"author": "ğŸ‘¤", "year": "ğŸ“…", "title": "ğŸ“–"}

                parts = [f"{display_map[k]} {str(meta[k])[:50]}" for k in display_map if meta.get(k)]

                if parts:
                    st.write("**Metadados:**")
                    st.caption(" | ".join(parts))

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("PÃ¡ginas", result["stats"]["total_pages"])
                with col2:
                    st.metric("Chunks", result["stats"]["total_chunks"])
                with col3:
                    st.metric("mÃ©dia/Chunk", f"{result['stats']['avg_chunk_size']:.0f} chars")

                #Mostra Preview dos primeiros chunks
                with st.expander("ğŸ” Preview dos Chunks"):
                    from src.utils import format_document_for_display

                    for j, doc in enumerate(result["documents"][:3], 1):
                        st.markdown(f"**Chunk {j}:**")
                        st.text(format_document_for_display(doc, max_length=300))
                        st.divider()

            else:
                st.error(f"âŒ **{uploaded_files[i-1].name}**: {result['error']}")

        st.session_state.processed_docs = all_results
        st.session_state.processing_done = True
        


    # Mostrar lista de arquivos
    with st.expander("ğŸ“‹ Arquivos Carregados"):
        for i, file in enumerate(uploaded_files, 1):
            st.write(f"{i}. {file.name} ({file.size / 1024:.1f} KB)")
else:
    st.info("ğŸ‘† Comece fazendo upload de papers cientÃ­ficos")

if st.session_state.get("processing_done"):
            st.markdown("---")
            st.subheader("ğŸ”§ Configurar Sistema RAG")

            # Mostra qual embedding estÃ¡ selecionado
            if st.session_state.get("selected_embedding_name"):
                st.info(f"ğŸ§  Modelo selecionado: **{st.session_state.selected_embedding_name}**")
    

            if st.button("âš™ï¸ Criar Banco Vetorial", type="primary"):
                from src.rag_engine import RAGEngine

                #coleta todos os chunks proessados
                all_chunks = []
                for result in st.session_state.processed_docs:
                    if result["success"]:
                        all_chunks.extend(result["documents"])

                if not all_chunks:
                    st.error("Nenhum documento processado com sucesso")
                    st.stop()

                embedding_model = st.session_state.get(
                    "selected_embedding_model",
                    EMBEDDING_CONFIG["model_name"]
                )
                 #Cria nome de collection Ãºnico baseado no embedding
                # Isso permite ter mÃºltiplas versÃµes com embeddings diferentes
                embedding_collection_map = {
                    "MiniLM (RÃ¡pido)": "papers_minilm",
                    "Nomic Embed (Balanceado)": "papers_nomic",
                    "BGE-M3 (Premium)": "papers_bge_m3"
                }

                collection_name = embedding_collection_map.get(
                    st.session_state.selected_embedding_name,
                    "papers_default"
)

                with st.spinner(f"Criando banco vetorial com {len(all_chunks)} chunks..."):
                    try:
                        # Cria o motor RAG
                        rag_engine = RAGEngine(
                            embedding_model=embedding_model,
                            collection_name=collection_name
                    )
                        
                        # Cria vectorstore
                        rag_engine.create_vectorstore(all_chunks)
                        
                        # Cria retriever
                        rag_engine.create_retriever()
                        
                        # Salva no session_state
                        st.session_state.rag_engine = rag_engine
                        st.session_state.rag_ready = True
                        st.session_state.current_embedding = st.session_state.selected_embedding_name
                        st.success("âœ… Sistema RAG criado com sucesso!")
                        
                        # Mostra estatÃ­sticas
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Total de Chunks", len(all_chunks))
                        with col2:
                            st.metric("Embedding", st.session_state.selected_embedding_name.split()[0])
                        with col3:
                            st.metric("DimensÃµes", EMBEDDING_OPTIONS[st.session_state.selected_embedding_name]["dimensions"])
                        with col4:
                            st.metric("Collection", collection_name[:15] + "...")
                    except Exception as e:
                        st.error(f"Erro ao criar sistema RAG: {str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
                        st.stop()
                
# Ãrea de perguntas (CORRIGIDA)
st.markdown("---")
st.subheader("ğŸ’¬ FaÃ§a sua Pergunta")

# Inicializa variÃ¡veis de filtro
use_author_filter = False
use_year_filter = False
selected_author = None
selected_year = None

if not st.session_state.get("rag_ready"):
    st.info("ğŸ‘† Processe os documentos e crie o banco vetorial primeiro")
    pergunta = st.text_area(
        "Digite sua pergunta sobre os papers",
        height=100,
        disabled=True,
        placeholder="Configure o sistema RAG primeiro..."
    )
else:
    # FILTROS DE BUSCA (sÃ³ aparece se RAG estÃ¡ pronto)
    st.markdown("#### ğŸ” Filtros de Busca (Opcional)")
    
    # Coletar autores e anos disponÃ­veis
    available_authors = set()
    available_years = set()
    
    if st.session_state.get("processed_docs"):
        for result in st.session_state.processed_docs:
            if result["success"]:
                meta = result["metadata"]
                if meta.get("author"):
                    available_authors.add(meta["author"])
                if meta.get("year"):
                    available_years.add(meta["year"])
    
    filter_col1, filter_col2, filter_col3 = st.columns(3)
    
    with filter_col1:
        use_author_filter = st.checkbox("Filtrar por Autor")
        if use_author_filter and available_authors:
            selected_author = st.selectbox(
                "Selecione o autor",
                options=["Todos"] + sorted(list(available_authors)),
                key="filter_author"
            )
            if selected_author == "Todos":
                selected_author = None
    
    with filter_col2:
        use_year_filter = st.checkbox("Filtrar por Ano")
        if use_year_filter and available_years:
            selected_year = st.selectbox(
                "Selecione o ano",
                options=["Todos"] + sorted(list(available_years), reverse=True),
                key="filter_year"
            )
            if selected_year == "Todos":
                selected_year = None
    
    with filter_col3:
        st.write("")  # EspaÃ§amento
        st.caption("ğŸ’¡ Use filtros para comparar estudos especÃ­ficos")
    
    st.divider()
    
    # TEXT AREA DE PERGUNTA
    pergunta = st.text_area(
        "Digite sua pergunta sobre os papers",
        height=100,
        placeholder="Ex: Quais metodologias foram utilizadas?"
    )

# BOTÃƒO DE ANALISAR (fora do if/else para sempre estar disponÃ­vel)
btn_col1, btn_col2 = st.columns([1, 5])
with btn_col1:
    btn_perguntar = st.button(
        "ğŸ” Analisar", 
        type="primary", 
        disabled=not st.session_state.get("rag_ready")
    )

# PROCESSAMENTO DA PERGUNTA
if btn_perguntar and pergunta:
    with st.spinner("ğŸ¤” Analisando papers e gerando resposta..."):
        try:
            # Determina se usa filtros
            author_filter = selected_author if (use_author_filter and selected_author) else None
            year_filter = int(selected_year) if (use_year_filter and selected_year) else None
            
            # Faz query com ou sem filtros
            if author_filter or year_filter:
                result = st.session_state.rag_engine.query_with_filters(
                    question=pergunta,
                    author=author_filter,
                    year=year_filter,
                    return_sources=True
                )
                
                # Mostra filtros aplicados
                filters_info = []
                if author_filter:
                    filters_info.append(f"ğŸ‘¤ Autor: **{author_filter}**")
                if year_filter:
                    filters_info.append(f"ğŸ“… Ano: **{year_filter}**")
                st.info("ğŸ” Filtros aplicados: " + " | ".join(filters_info))
            else:
                result = st.session_state.rag_engine.query(
                    question=pergunta,
                    return_sources=True
                )

            with st.expander("ğŸ› DEBUG - Chunks Recuperados (clique para ver)"):
                for i, doc in enumerate(result["sources"], 1):
                    st.markdown(f"**Chunk {i} (score de similaridade):**")
                    st.markdown(f"- **Arquivo:** {doc.metadata.get('source_file', 'N/A')}")
                    st.markdown(f"- **PÃ¡gina:** {doc.metadata.get('page', '?')}")
                    st.markdown(f"- **Autor:** {doc.metadata.get('author', 'N/A')}")
                    st.text(doc.page_content[:400] + "..." if len(doc.page_content) > 400 else doc.page_content)
                    st.divider()

            # Exibe resposta
            st.markdown("### ğŸ“ Resposta")
            st.write(result["answer"])
            
            # Exibe fontes usadas
            st.markdown("---")
            st.markdown("### ğŸ“š Fontes Consultadas")
            
            for i, doc in enumerate(result["sources"], 1):
                with st.expander(f"ğŸ“„ Fonte {i}: {doc.metadata.get('source_file', 'N/A')} - PÃ¡gina {doc.metadata.get('page', '?')}"):
                    st.text(doc.page_content[:500] + "..." if len(doc.page_content) > 500 else doc.page_content)
            
            # Exibe metadados
            with st.expander("â„¹ï¸ InformaÃ§Ãµes da Consulta"):
                st.json(result["metadata"])
        
        except Exception as e:
            st.error(f"Erro ao processar pergunta: {str(e)}")

# ==================== SÃNTESE DE LITERATURA (FEATURE PRINCIPAL) ====================
if st.session_state.get("rag_ready") and st.session_state.get("processed_docs"):
    st.markdown("---")
    st.markdown("## ğŸ“š SÃ­ntese de Literatura Automatizada")
    
    st.info("""
    **ğŸ¯ Feature Diferenciada:** AnÃ¡lise comparativa automÃ¡tica de mÃºltiplos papers acadÃªmicos.
    
    **Como funciona:**
    1. **MAP:** Cada paper Ã© analisado individualmente focando no aspecto escolhido
    2. **REDUCE:** Os resumos sÃ£o sintetizados em uma comparaÃ§Ã£o estruturada
    3. **EXPORT:** Resultado disponÃ­vel em Markdown/TXT para uso em trabalhos acadÃªmicos
    """)
    
    # Verifica quantos papers foram processados
    total_papers = len([r for r in st.session_state.processed_docs if r["success"]])
    
    if total_papers < 2:
        st.warning(f"âš ï¸ VocÃª tem apenas {total_papers} paper(s). Carregue pelo menos 2 para comparaÃ§Ã£o.")
    else:
        st.success(f"âœ… {total_papers} papers prontos para sÃ­ntese comparativa")
        
        # ConfiguraÃ§Ãµes da sÃ­ntese
        col1, col2 = st.columns([2, 1])
        
        with col1:
            synthesis_focus = st.selectbox(
                "ğŸ¯ Foco da AnÃ¡lise",
                options=["completo", "metodologia", "resultados", "limitacoes"],
                help="Escolha o aspecto que deseja comparar entre os papers"
            )
        
        with col2:
            include_individual = st.checkbox(
                "Incluir resumos individuais",
                value=True,
                help="AlÃ©m da sÃ­ntese comparativa, incluir resumo de cada paper"
            )
        
        # DescriÃ§Ãµes dos focos
        focus_descriptions = {
            "completo": "ğŸ“– **RevisÃ£o Completa:** Objetivo, metodologia, resultados e conclusÃµes de cada paper",
            "metodologia": "ğŸ”¬ **Metodologias:** Foca em mÃ©todos, tÃ©cnicas, amostras e anÃ¡lises estatÃ­sticas",
            "resultados": "ğŸ“Š **Resultados:** Foca em achados principais, dados quantitativos e significÃ¢ncia",
            "limitacoes": "âš ï¸ **LimitaÃ§Ãµes:** Foca em problemas metodolÃ³gicos e gaps de pesquisa"
        }
        
        st.markdown(focus_descriptions[synthesis_focus])
        
        st.divider()
        
        # BotÃ£o principal
        if st.button("ğŸš€ Gerar RevisÃ£o de Literatura", type="primary", use_container_width=True):
            from src.synthesis import PaperSynthesizer
            
            # Agrupa chunks por paper
            papers_documents = {}
            for result in st.session_state.processed_docs:
                if result["success"]:
                    source_file = result["metadata"]["source_file"]
                    papers_documents[source_file] = result["documents"]
            
            # Estimativa de tempo
            estimated_time = len(papers_documents) * 15  # ~15s por paper
            
            with st.spinner(f"â³ Processando {len(papers_documents)} papers... (tempo estimado: ~{estimated_time}s)"):
                try:
                    # Progress bar
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # Callback para atualizar progresso (simulado)
                    import time
                    
                    status_text.text("ğŸ“– Fase MAP: Analisando papers individuais...")
                    progress_bar.progress(0.2)
                    
                    # Cria sintetizador
                    synthesizer = PaperSynthesizer(st.session_state.rag_engine.llm)
                    
                    # Gera revisÃ£o
                    review = synthesizer.generate_literature_review(
                        papers_documents,
                        focus=synthesis_focus,
                        include_individual=include_individual
                    )
                    
                    progress_bar.progress(0.8)
                    status_text.text("ğŸ”„ Fase REDUCE: Gerando sÃ­ntese comparativa...")
                    
                    # Exporta para Markdown
                    markdown_output = synthesizer.export_to_markdown(review)
                    
                    progress_bar.progress(1.0)
                    status_text.text("âœ… RevisÃ£o de literatura concluÃ­da!")
                    
                    time.sleep(0.5)
                    progress_bar.empty()
                    status_text.empty()
                    
                    # Salva no session_state para nÃ£o perder
                    st.session_state.last_review = {
                        "result": review,
                        "markdown": markdown_output,
                        "timestamp": datetime.datetime.now()
                    }
                    
                    # MÃ©tricas da anÃ¡lise
                    st.markdown("### ğŸ“Š MÃ©tricas da AnÃ¡lise")
                    metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
                    
                    with metric_col1:
                        st.metric("Papers Analisados", f"{review['successful_analyses']}/{review['total_papers']}")
                    with metric_col2:
                        st.metric("Tempo de Processamento", f"{review['duration_seconds']:.1f}s")
                    with metric_col3:
                        st.metric("Palavras Geradas", review['total_words'])
                    with metric_col4:
                        focus_emoji = {"completo": "ğŸ“–", "metodologia": "ğŸ”¬", "resultados": "ğŸ“Š", "limitacoes": "âš ï¸"}
                        st.metric("Foco", f"{focus_emoji.get(synthesis_focus, 'ğŸ“„')} {synthesis_focus.title()}")
                    
                    st.divider()
                    
                    # Exibe sÃ­ntese comparativa
                    st.markdown("### ğŸ“Š SÃ­ntese Comparativa")
                    st.markdown(review["comparative_synthesis"])
                    
                    # Resumos individuais (se solicitado)
                    if include_individual and "individual_summaries" in review:
                        st.markdown("---")
                        st.markdown("### ğŸ“„ Resumos Individuais")
                        
                        for i, summary in enumerate(review["individual_summaries"], 1):
                            if summary["success"]:
                                meta = summary["metadata"]
                                author = meta.get("author", "Autor desconhecido")
                                year = meta.get("year", "?")
                                source = meta.get("source_file", "Documento")
                                
                                with st.expander(f"ğŸ“‘ Paper {i}: {author} ({year}) - {source[:40]}..."):
                                    st.markdown(summary["summary"])
                                    st.caption(f"ğŸ’¬ {summary['word_count']} palavras")
                    
                    # BotÃµes de export
                    st.markdown("---")
                    st.markdown("### â¬‡ï¸ Exportar RevisÃ£o")
                    
                    export_col1, export_col2, export_col3 = st.columns(3)
                    
                    with export_col1:
                        st.download_button(
                            "ğŸ“ Download Markdown",
                            data=markdown_output,
                            file_name=f"revisao_literatura_{synthesis_focus}_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.md",
                            mime="text/markdown",
                            use_container_width=True
                        )
                    
                    with export_col2:
                        st.download_button(
                            "ğŸ“„ Download TXT",
                            data=markdown_output,
                            file_name=f"revisao_literatura_{synthesis_focus}_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                            mime="text/plain",
                            use_container_width=True
                        )
                    
                    with export_col3:
                        # Copia para clipboard (via botÃ£o)
                        if st.button("ğŸ“‹ Copiar Texto", use_container_width=True):
                            st.toast("âœ… Texto copiado! Use Ctrl+V para colar")
                            st.code(markdown_output[:500] + "\n...\n[Use o botÃ£o de download para texto completo]")
                
                except Exception as e:
                    st.error(f"âŒ Erro ao gerar revisÃ£o: {str(e)}")
                    import traceback
                    with st.expander("ğŸ› Detalhes do Erro (para debug)"):
                        st.code(traceback.format_exc())

# Mostra Ãºltima revisÃ£o gerada (se houver)
if st.session_state.get("last_review"):
    with st.expander("ğŸ•’ Ãšltima RevisÃ£o Gerada", expanded=False):
        last = st.session_state.last_review
        st.caption(f"Gerada em: {last['timestamp'].strftime('%d/%m/%Y Ã s %H:%M:%S')}")
        
        st.download_button(
            "â¬‡ï¸ Re-download da Ãšltima RevisÃ£o",
            data=last["markdown"],
            file_name=f"revisao_ultima.md",
            mime="text/markdown"
        )

# Footer
st.markdown("---")
st.caption("Desenvolvido para portfÃ³lio de JoÃ£o OtÃ¡vio Mochiuti | Powered by LangChain + Llama 3.3 70B via Groq")